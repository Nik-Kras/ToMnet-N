{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMcwg/75gtXtOc1okOlp7qb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nik-Kras/ToMnet-N/blob/Move_To_Keras/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "class CharNet(nnl.NeuralNetLayers):\n",
        "\n",
        "For the single trajectory τi in the past episode, the\n",
        "ToMnet forms the character embedding echar,i as follows. We\n",
        " (1) pre-process the data from each time-step by spatialising the actions,\n",
        " a(obs), concatenating these with the respective states, x(obs),\n",
        " (2) passing through a 5-layer resnet, with 32 channels, ReLU nonlinearities,\n",
        " and batch-norm, followed by average pooling.\n",
        " (3) We pass the results through an LSTM with 64 channels,\n",
        " with a linear output to either a 2-dim or 8-dim echar,i (no substantial difference in results).\n",
        "@author: Chuang, Yun-Shiuan; Edwinn\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "# from keras.layers import Input\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LSTM\n",
        "from keras import activations\n",
        "\n",
        "class CustomCnn(keras.layers.Layer):\n",
        "  def __init__(self, input_tensor=None, activation=\"linear\", filters=32):\n",
        "        super(CustomCnn, self).__init__()\n",
        "        if input_tensor is None:\n",
        "          self.conv = tf.keras.layers.Conv2D(filters=filters,\n",
        "                                  kernel_size=(3, 3),\n",
        "                                  strides=(1, 1),\n",
        "                                  activation=activation,\n",
        "                                  padding=\"same\")\n",
        "        else:\n",
        "          self.conv = tf.keras.layers.Conv2D(filters=filters,\n",
        "                                  kernel_size=(3, 3),\n",
        "                                  strides=(1, 1),\n",
        "                                  activation=activation,\n",
        "                                  padding=\"same\",\n",
        "                                  input_shape=input_tensor)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.conv(x)\n",
        "    return x\n",
        "\n",
        "class ResBlock(keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv1 = CustomCnn(activation=\"relu\")\n",
        "        # Use Batch Normalisation and then Relu activation in future!\n",
        "        self.conv1_handler = tf.keras.layers.TimeDistributed(self.conv1)\n",
        "        self.conv2 = CustomCnn(activation=\"linear\")\n",
        "        # Use Batch Normalisation in future!\n",
        "        self.conv2_handler = tf.keras.layers.TimeDistributed(self.conv2)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.conv1_handler(inputs)\n",
        "    x = self.conv2_handler(x)\n",
        "    x = tf.nn.relu(x + inputs)\n",
        "    return x\n",
        "\n",
        "class CustomLSTM(keras.layers.Layer):\n",
        "  def __init__(self, num_hidden = 64, output_keep_prob = 0.2):\n",
        "    super(CustomLSTM, self).__init__()\n",
        "    self.lstm = LSTM(units=num_hidden,\n",
        "                    activation = activations.tanh,\n",
        "                    recurrent_activation = activations.sigmoid,\n",
        "                    recurrent_dropout = output_keep_prob,\n",
        "                    dropout = output_keep_prob)\n",
        "    self.bn = BatchNormalization()\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.lstm(inputs)\n",
        "    x = self.bn(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "AjCQ6cRUhO8d"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------\n",
        "# CharNet is a layer, as it doesn't have separate and own training,\n",
        "# it is simply a part of whole network, so can be considered as a layer\n",
        "# --------------------------------------------------------------\n",
        "class CharNet(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, input_tensor, n, N_echar):\n",
        "        super(CharNet, self).__init__()\n",
        "\n",
        "        # self.input_tensor = input_tensor\n",
        "        self.n = n\n",
        "        self.N_echar = N_echar\n",
        "\n",
        "        self.conv = CustomCnn(input_tensor=input_tensor)\n",
        "        self.res_blocks = [None] * n\n",
        "        for i in range(n):\n",
        "          self.res_blocks[i] = ResBlock()\n",
        "        # Global Pool\n",
        "        self.lstm = CustomLSTM()\n",
        "        self.e_char = Dense(N_echar)\n",
        "        \n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Build the character net.\n",
        "        \"\"\"\n",
        "\n",
        "        # input_tensor = self.input_tensor\n",
        "        n = self.n\n",
        "        N_echar = self.N_echar\n",
        "\n",
        "        batch_size, trajectory_size, height, width, depth  = inputs.get_shape().as_list()\n",
        "\n",
        "        # --------------------------------------------------------------\n",
        "        # Paper codes\n",
        "        # (16, 10, 12, 12, 11) -> (16, 10, 12, 12, 32)\n",
        "        # Add initial Conv2D layer\n",
        "        # Conv2D standard: Shape = (batch_size, width, height, channels)\n",
        "        # Conv2D takes only width x height x channels (12, 12, 11)\n",
        "        # Time Distributed layer feeds a Conv2D with time-frames (10 frames)\n",
        "        # That process is happening in parallel for 16 objects in one batch\n",
        "        # --------------------------------------------------------------\n",
        "        # inputs = tf.keras.Input(shape=(trajectory_size, height, width, depth), batch_size=batch_size) # This is for model definition, not layer definition\n",
        "        conv_2d_layer = tf.keras.layers.Conv2D(filters=32,\n",
        "                                             kernel_size=(3, 3),\n",
        "                                             strides=(1, 1),\n",
        "                                             # activation='relu',\n",
        "                                             padding=\"same\",\n",
        "                                             input_shape=(height, width, depth))  # kernel_size=(3, 3) ? (11,11) ? If an input image has 3 channels (e.g. a depth of 3), then a filter applied to that image must also have 3 channels (e.g. a depth of 3). In this case, a 3×3 filter would in fact be 3x3x3\n",
        "        conv_2d_handler = tf.keras.layers.TimeDistributed(conv_2d_layer)(inputs)\n",
        "\n",
        "        print(\"The input data: \", inputs.shape)\n",
        "        print(\"The shape for Conv2D Handler: \", conv_2d_handler.shape)\n",
        "\n",
        "        # --------------------------------------------------------------\n",
        "        # Paper codes\n",
        "        # (16, 10, 12, 12, 11) -> (16, 10, 12, 12, 32)\n",
        "        # Add n residual layers\n",
        "        # Conv2D takes only width x height x channels (12, 12, 11)\n",
        "        # Time Distributed layer feeds a Conv2D with time-frames (10 frames)\n",
        "        # That process is happening in parallel for 16 objects in one batch\n",
        "        # --------------------------------------------------------------\n",
        "        res_layers = [None] * n\n",
        "        prev_layer = conv_2d_handler\n",
        "        for i in range(n):\n",
        "            # Conv2D to process 12x12x11 time-frame\n",
        "            conv_layer = tf.keras.layers.Conv2D(filters=32,\n",
        "                                                 kernel_size=(3, 3),\n",
        "                                                 strides=(1, 1),\n",
        "                                                 padding=\"same\",\n",
        "                                                 input_shape=(height, width, depth))\n",
        "            # Thing that will pass 10 time frames iteratively to Conv2D. Outputs 10x12x12x11\n",
        "            conv_layer_handler = tf.keras.layers.TimeDistributed(conv_layer)(prev_layer)\n",
        "\n",
        "            # NIKITA: ORIGINALLY I MUST INCLUDE BATCH NORMALISATION HERE, BUT I DON'T SEE SENSE IN IT\n",
        "            # Normalize the whole batch\n",
        "            # mean, variance = tf.nn.moments(x=input_layer, axes=[0, 1, 2])\n",
        "            # batch_norm = BatchNormalization()\n",
        "            # bn_layer = self.batch_normalization_layer(conv_layer, out_channel)\n",
        "            ### res_batch_1 = BatchNormalization(axes=[2, 3, 4])(conv_layer_handler)  # If want to add Normalisation - Use this!\n",
        "            res_conv_1 = tf.nn.relu(conv_layer_handler)\n",
        "\n",
        "            # Conv2D to process 12x12x11 time-frame\n",
        "            conv_layer_2 = tf.keras.layers.Conv2D(filters=32,\n",
        "                                                kernel_size=(3, 3),\n",
        "                                                strides=(1, 1),\n",
        "                                                padding=\"same\",\n",
        "                                                input_shape=(height, width, depth))\n",
        "            # Thing that will pass 10 time frames iteratively to Conv2D. Outputs 10x12x12x11\n",
        "            conv_layer_handler_2 = tf.keras.layers.TimeDistributed(conv_layer_2)(res_conv_1)\n",
        "            res_conv_2 = conv_layer_handler_2\n",
        "\n",
        "            res_layers[i] = tf.nn.relu(res_conv_2 + prev_layer)\n",
        "            prev_layer = res_layers[i]\n",
        "\n",
        "        # --------------------------------------------------------------\n",
        "        # Paper codes\n",
        "        # (16, 10, 12, 12, 32) ->  (16, 10, 32)\n",
        "        # Add average pooling\n",
        "        # Collapse the spatial dimensions\n",
        "        # --------------------------------------------------------------\n",
        "        global_pool = tf.reduce_mean(input_tensor=prev_layer, axis=[2, 3])\n",
        "\n",
        "        # --------------------------------------------------------------\n",
        "        # Paper codes\n",
        "        # (16, 10, 32) ->  (16, 64)\n",
        "        # Add LSTM\n",
        "        # Standard: Shape = (batch_size, time_step, features)\n",
        "        # for each x_i(t)(example_i's step_t): a (64, 1) = W(64, 32) * x (32, 1)\n",
        "        # --------------------------------------------------------------\n",
        "        num_hidden = 64\n",
        "        output_keep_prob = 0.2  # Regularization during training\n",
        "        lstm_layer = LSTM(units=num_hidden,\n",
        "                        activation = activations.tanh,\n",
        "                        recurrent_activation = activations.sigmoid,\n",
        "                        recurrent_dropout = output_keep_prob,\n",
        "                        dropout = output_keep_prob)(global_pool)\n",
        "        lstm_batch_norm = BatchNormalization()(lstm_layer)\n",
        "\n",
        "        # --------------------------------------------------------------\n",
        "        # Paper codes\n",
        "        # (16, 64) -> (16, 4)\n",
        "        # Add Fully connected layer\n",
        "        # (batch_size, features) - > (batch_size, e_char)\n",
        "        # --------------------------------------------------------------\n",
        "        e_char = Dense(N_echar)(lstm_batch_norm)\n",
        "\n",
        "        return e_char\n"
      ],
      "metadata": {
        "id": "h-8Qn58YWZNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTbqasPnWQii"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "# from keras.layers import Input\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras import activations\n",
        "from keras.layers import Concatenate\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# CharNet is a layer, as it doesn't have separate and own training,\n",
        "# it is simply a part of whole network, so can be considered as a layer\n",
        "# --------------------------------------------------------------\n",
        "class PredNet(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, n):\n",
        "        super(PredNet, self).__init__()\n",
        "        self.n = n\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Build the character net.\n",
        "        \"\"\"\n",
        "\n",
        "        n = self.n\n",
        "\n",
        "        # --------------------------------------------------------------\n",
        "        # Paper codes\n",
        "        # (16, 13, 12, 8)-> (16, 12, 12, 6) + (16, 8)\n",
        "        # Decompose input data\n",
        "        # Initially in is a mix of Current State and e_char embedding space\n",
        "        # --------------------------------------------------------------\n",
        "        # e_char = inputs[\"e_char\"]\n",
        "        # current_state_tensor = inputs[\"input_current_state\"]\n",
        "        input_current_state = inputs[..., 0:12, 0:12, 0:6]\n",
        "        e_char = inputs[..., 12, 0, :]\n",
        "\n",
        "        # --------------------------------------------------------------\n",
        "        # Paper codes\n",
        "        # Get the tensor size: (16, 12, 12, 6) <-> (batch size, height, width, channels)\n",
        "        # --------------------------------------------------------------\n",
        "        batch_size, height, width, depth = input_current_state.get_shape().as_list()\n",
        "\n",
        "        # --------------------------------------------------------------\n",
        "        # Paper codes\n",
        "        # Get the character embedding size: (16, 8) <-> (batch size, e_char)\n",
        "        # --------------------------------------------------------------\n",
        "        _, embedding_length = e_char.get_shape().as_list()\n",
        "\n",
        "        # --------------------------------------------------------------\n",
        "        # Paper codes\n",
        "        # (16, 12, 12, 6) -> (16, 12, 12, 32)\n",
        "        # Use 3x3 conv layer to shape the depth to 32\n",
        "        # to enable resnet to work (addition between main path and residual connection)\n",
        "        # --------------------------------------------------------------\n",
        "        conv_2d_layer = tf.keras.layers.Conv2D(filters=32,\n",
        "                               kernel_size=(3, 3),\n",
        "                               strides=(1, 1),\n",
        "                               # activation='relu',\n",
        "                               padding=\"same\",\n",
        "                               input_shape=(height, width, depth))(input_current_state)\n",
        "\n",
        "        # --------------------------------------------------------------\n",
        "        # Paper codes\n",
        "        # (16, 12, 12, 32) -> (16, 12, 12, 32)\n",
        "        # Add n residual layers\n",
        "        # Conv2D takes only width x height x channels (12, 12, 11)\n",
        "        # Time Distributed layer feeds a Conv2D with time-frames (10 frames)\n",
        "        # That process is happening in parallel for 16 objects in one batch\n",
        "        # --------------------------------------------------------------\n",
        "        res_layers = [None] * n\n",
        "        prev_layer = conv_2d_layer\n",
        "        for i in range(n):\n",
        "\n",
        "            conv_layer = tf.keras.layers.Conv2D(filters=32,\n",
        "                                                kernel_size=(3, 3),\n",
        "                                                strides=(1, 1),\n",
        "                                                padding=\"same\",\n",
        "                                                input_shape=(height, width, depth))(prev_layer)\n",
        "\n",
        "            ### res_batch_1 = BatchNormalization(axes=[2, 3, 4])(conv_layer)  # If want to add Normalisation - Use this!\n",
        "            res_conv_1 = tf.nn.relu(conv_layer)\n",
        "\n",
        "            conv_layer_2 = tf.keras.layers.Conv2D(filters=32,\n",
        "                                                  kernel_size=(3, 3),\n",
        "                                                  strides=(1, 1),\n",
        "                                                  padding=\"same\",\n",
        "                                                  input_shape=(height, width, depth))(res_conv_1)\n",
        "\n",
        "            res_conv_2 = conv_layer_2\n",
        "\n",
        "            res_layers[i] = tf.nn.relu(res_conv_2 + prev_layer)\n",
        "            prev_layer = res_layers[i]\n",
        "\n",
        "        # --------------------------------------------------------------\n",
        "        # Paper codes\n",
        "        # (16, 12, 12, 32) -> (16, 12, 12, 32)\n",
        "        # Add CNN after Res Blocks\n",
        "        # --------------------------------------------------------------\n",
        "        conv_2d_layer_after_res = tf.keras.layers.Conv2D(filters=32,\n",
        "                                                       kernel_size=(3, 3),\n",
        "                                                       strides=(1, 1),\n",
        "                                                       activation='relu',\n",
        "                                                       padding=\"same\",\n",
        "                                                       input_shape=(height, width, depth))(prev_layer)\n",
        "\n",
        "        # --------------------------------------------------------------\n",
        "        # Paper codes\n",
        "        # (16, 12, 12, 32) -> (16, 32)\n",
        "        # Add average pooling\n",
        "        # Collapse the spatial dimensions\n",
        "        # --------------------------------------------------------------\n",
        "        global_pool = tf.reduce_mean(input_tensor=conv_2d_layer_after_res, axis=[1, 2])\n",
        "\n",
        "\n",
        "        # --------------------------------------------------------------\n",
        "        # Paper codes\n",
        "        # (16, 32) + (16, 8) -> (16, 32, 1) + (16, 8, 1) - > \n",
        "        # (16, 40, 1) -> (16, 40)\n",
        "        # Concatenate tensor with e_char\n",
        "        # Concatenation requires a common dimentions which cannot be a batch\n",
        "        # --------------------------------------------------------------\n",
        "        global_pool = tf.expand_dims(global_pool, axis=-1)\n",
        "        e_char = tf.expand_dims(e_char, axis=-1)\n",
        "\n",
        "        merge = tf.keras.layers.Concatenate(axis=1)([global_pool, e_char])\n",
        "        merge = merge[..., 0]\n",
        "\n",
        "        # --------------------------------------------------------------\n",
        "        # Paper codes\n",
        "        # (16, 40) -> (16, 60) -> (16, 4)\n",
        "        # Fully connected layer with dropout for regularization\n",
        "        # --------------------------------------------------------------\n",
        "        dense_1 = Dense(units=60, activation=activations.relu)(merge)\n",
        "        drop_out_1 = Dropout(rate = 0.2)(dense_1)\n",
        "        output = Dense(units=60, activation=activations.linear)(drop_out_1)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------\n",
        "# ToMnet-N represents the model itself\n",
        "# --------------------------------------\n",
        "from keras import Model\n",
        "\n",
        "class ToMnet_N(Model):\n",
        "\n",
        "    BATCH_SIZE = 16\n",
        "    TRAJECTORY_SHAPE = (10, 12, 12, 11)\n",
        "    CURRENT_STATE_SHAPE = (12, 12, 6)\n",
        "\n",
        "    LENGTH_E_CHAR = 8\n",
        "    NUM_RESIDUAL_BLOCKS = 5\n",
        "\n",
        "    TRAIN_EMA_DECAY = 0.95\n",
        "    INIT_LR = 0.0001\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ToMnet_N, self).__init__(name=\"ToMnet-N\")\n",
        "\n",
        "        # Create the model\n",
        "        self.char_net = CharNet(input_tensor=self.TRAJECTORY_SHAPE,\n",
        "                              n=self.NUM_RESIDUAL_BLOCKS,\n",
        "                              N_echar=self.LENGTH_E_CHAR)\n",
        "\n",
        "        self.pred_net = PredNet(n=self.NUM_RESIDUAL_BLOCKS)\n",
        "\n",
        "        # Set compilers / savers / loggers / callbacks\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_trajectory = inputs[..., 0:10, :, :, :]\n",
        "        input_current_state = inputs[..., 10, :, :, 0:6]\n",
        "\n",
        "        e_char = self.char_net(input_trajectory)\n",
        "\n",
        "        print(\"In ToMnet-N: \")\n",
        "        print(\"input_trajectory: \", input_trajectory.shape)\n",
        "        print(\"input_current_state: \", input_current_state.shape)\n",
        "        print(\"e_char: \", e_char.shape)\n",
        "\n",
        "        # --------------------------------------------------------------\n",
        "        # Paper codes\n",
        "        # (16, 12, 12, 6) + (16, 8) -> \n",
        "        # (16, 12, 12, 8) + (16, 1, 12, 8) -> (16, 13, 12, 8)\n",
        "        # Spatialise and unite different data into one tensor\n",
        "        # They are automatically decompose in the Pred Net to different data\n",
        "        # --------------------------------------------------------------\n",
        "        input_current_state = tf.repeat(input_current_state, repeats=2, axis=-1)\n",
        "        input_current_state = input_current_state[..., 0:8]\n",
        "        print(\"input_current_state: \", input_current_state.shape)\n",
        "    \n",
        "        e_char =  tf.expand_dims(e_char, axis=1)\n",
        "        print(\"e_char: \", e_char.shape)\n",
        "        e_char =  tf.expand_dims(e_char, axis=1)\n",
        "        print(\"e_char: \", e_char.shape)\n",
        "        e_char = tf.repeat(e_char, repeats=12, axis=2)\n",
        "        print(\"e_char: \", e_char.shape)\n",
        "\n",
        "        mix_data = tf.keras.layers.Concatenate(axis=1)([input_current_state, e_char])\n",
        "\n",
        "        print(\"pred input: \", mix_data.shape)\n",
        "\n",
        "        pred = self.pred_net(mix_data)\n",
        "        output = pred\n",
        "        return output"
      ],
      "metadata": {
        "id": "Lj_bTetoWiIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([[1,2,3],[4,5,6]], tf.int32)\n",
        "b = tf.constant([1 ,1, 1, 1], tf.int32)\n",
        "tf.tile(a[:, :, None, None], b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Snn7MsXRe7dP",
        "outputId": "b8db2ec8-fd1a-4a77-a6e1-f728f1cf1c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3, 1, 1), dtype=int32, numpy=\n",
              "array([[[[1]],\n",
              "\n",
              "        [[2]],\n",
              "\n",
              "        [[3]]],\n",
              "\n",
              "\n",
              "       [[[4]],\n",
              "\n",
              "        [[5]],\n",
              "\n",
              "        [[6]]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 410
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_data_1 = tf.ones((10, 12, 12, 11))\n",
        "dummy_data_2 = tf.ones((12, 12, 6))\n",
        "\n",
        "dummy_data_3 = tf.zeros((12, 12, 5))\n",
        "\n",
        "dummy_data_2_u  = tf.concat([dummy_data_2, dummy_data_3], -1)\n",
        "\n",
        "dummy_data_2_uu = tf.expand_dims(dummy_data_2_u, 0)\n",
        "\n",
        "combined_data = tf.concat([dummy_data_1, dummy_data_2_uu], axis=0)\n",
        "\n",
        "\n",
        "print(\"Shape data 1: \", dummy_data_1.shape)\n",
        "print(\"Shape data 2: \", dummy_data_2.shape)\n",
        "print(\"Shape data 3: \", dummy_data_3.shape)\n",
        "print(\"Shape data 2 updated: \", dummy_data_2_u.shape)\n",
        "print(\"Shape data 2 updated twice: \", dummy_data_2_uu.shape)\n",
        "print(\"Output shape: \", combined_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-hBBfDhfVns",
        "outputId": "de3220b9-0596-4ef4-bf5e-f07e27f40293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape data 1:  (10, 12, 12, 11)\n",
            "Shape data 2:  (12, 12, 6)\n",
            "Shape data 3:  (12, 12, 5)\n",
            "Shape data 2 updated:  (12, 12, 11)\n",
            "Shape data 2 updated twice:  (1, 12, 12, 11)\n",
            "Output shape:  (11, 12, 12, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_data_1 = tf.ones((10, 12, 12, 11))\n",
        "dummy_data_2 = tf.ones((12, 12, 6))\n",
        "\n",
        "dummy_data_3 = tf.expand_dims(dummy_data_2, axis=0)\n",
        "\n",
        "dummy_data_4 = tf.repeat(dummy_data_3, repeats=2, axis=-1)[:,:,:,0:11]\n",
        "\n",
        "dummy_combined = tf.keras.layers.Concatenate(axis=0)([dummy_data_1, dummy_data_4])\n",
        "\n",
        "print(\"Shape data 1: \", dummy_data_1.shape)\n",
        "print(\"Shape data 2: \", dummy_data_2.shape)\n",
        "print(\"Shape data 3: \", dummy_data_3.shape)\n",
        "print(\"Shape data 4: \", dummy_data_4.shape)\n",
        "print(\"Combination: \", dummy_combined.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNbV19tZXySa",
        "outputId": "5322e019-4539-41c6-ee09-daebbaae04be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape data 1:  (10, 12, 12, 11)\n",
            "Shape data 2:  (12, 12, 6)\n",
            "Shape data 3:  (1, 12, 12, 6)\n",
            "Shape data 4:  (1, 12, 12, 11)\n",
            "Combination:  (11, 12, 12, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_trajectory = dummy_combined[0:10,:,:,:]\n",
        "input_current_state = dummy_combined[10,:,:,0:6]\n",
        "\n",
        "print(\"input_trajectory: \", input_trajectory.shape)\n",
        "print(\"input_current_state: \", input_current_state.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZD_kWkNNoda",
        "outputId": "c00b60c4-396e-4e31-a8f6-dfb8b55dcae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_trajectory:  (10, 12, 12, 11)\n",
            "input_current_state:  (12, 12, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dummy_combined.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EW8yj2kOGEY",
        "outputId": "725a83ab-339f-4ea8-980c-fde06feb36d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11, 12, 12, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e_char = tf.ones((8))\n",
        "dummy_data_2 = tf.ones((12, 12, 6))\n",
        "\n",
        "e_char_2 =  tf.expand_dims(e_char, axis=0)\n",
        "e_char_2 =  tf.expand_dims(e_char_2, axis=0)\n",
        "e_char_2 = tf.repeat(e_char_2, repeats=12, axis=1)\n",
        "\n",
        "dummy_data_2 = tf.repeat(dummy_data_2, repeats=2, axis=-1)\n",
        "dummy_data_2 = dummy_data_2[..., 0:8]\n",
        "\n",
        "mix_data = tf.keras.layers.Concatenate(axis=0)([e_char_2, dummy_data_2])\n",
        "\n",
        "print(\"dummy_data_2: \", dummy_data_2.shape)\n",
        "print(\"e_char: \", e_char.shape)\n",
        "print(\"e_char_2: \", e_char_2.shape)\n",
        "print(\"mix_data: \", mix_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "285u9Sd7O2GV",
        "outputId": "dec48149-a29f-42b1-8062-081edc6a6e6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dummy_data_2:  (12, 12, 8)\n",
            "e_char:  (8,)\n",
            "e_char_2:  (1, 12, 8)\n",
            "mix_data:  (13, 12, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e_char = mix_data[12,0,:]\n",
        "input_current_state = mix_data[0:12,:,0:6]\n",
        "\n",
        "print(e_char.shape)\n",
        "print(input_current_state.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLaQHWn3Qzz7",
        "outputId": "ad6bb849-8d5d-48b2-b1f6-61e50cd48e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8,)\n",
            "(12, 12, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add batch size!\n",
        "dummy_combined =  tf.expand_dims(dummy_combined, axis=0)\n",
        "dummy_combined = tf.repeat(dummy_combined, repeats=16, axis = 0)\n",
        "\n",
        "print(dummy_combined.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYP5p4qIUdFu",
        "outputId": "d56ae431-af81-4f8a-ac1f-74233d2bca4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16, 11, 12, 12, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ToMnet_N = ToMnet_N()\n",
        "ToMnet_N.predict(dummy_combined)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xV1ZS0ziX1D-",
        "outputId": "1b12faf5-a5e2-425d-ad77-fa3f273822ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input data:  (None, 10, 12, 12, 11)\n",
            "The shape for Conv2D Handler:  (None, 10, 12, 12, 32)\n",
            "In ToMnet-N: \n",
            "input_trajectory:  (None, 10, 12, 12, 11)\n",
            "input_current_state:  (None, 12, 12, 6)\n",
            "e_char:  (None, 8)\n",
            "input_current_state:  (None, 12, 12, 8)\n",
            "e_char:  (None, 1, 8)\n",
            "e_char:  (None, 1, 1, 8)\n",
            "e_char:  (None, 1, 12, 8)\n",
            "pred input:  (None, 13, 12, 8)\n",
            "global_pool:  Tensor(\"ToMnet-N/pred_net_29/ExpandDims:0\", shape=(None, 32, 1), dtype=float32)\n",
            "global_pool size:  (None, 32, 1)\n",
            "e_char:  Tensor(\"ToMnet-N/pred_net_29/ExpandDims_1:0\", shape=(None, 8, 1), dtype=float32)\n",
            "e_char size:  (None, 8, 1)\n",
            "merge:  Tensor(\"ToMnet-N/pred_net_29/strided_slice_2:0\", shape=(None, 40), dtype=float32)\n",
            "merge size:  (None, 40)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-418-bcbe556f46e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mToMnet_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToMnet_N\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mToMnet_N\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_combined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"ToMnet-N\" (type ToMnet_N).\n    \n    in user code:\n    \n        File \"<ipython-input-409-f6025da3fefa>\", line 36, in call  *\n            e_char = self.char_net(input_trajectory)\n        File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        ValueError: Exception encountered when calling layer \"char_net_29\" (type CharNet).\n        \n        in user code:\n        \n            File \"<ipython-input-173-6389f8f66b68>\", line 69, in call  *\n                conv_2d_handler = tf.keras.layers.TimeDistributed(conv_2d_layer)(inputs)\n            File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n        \n            ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.\n        \n        \n        Call arguments received:\n          • inputs=tf.Tensor(shape=(None, 10, 12, 12, 11), dtype=float32)\n    \n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 11, 12, 12, 11), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ToMnet_N.summary()"
      ],
      "metadata": {
        "id": "BE5_tiB0XXxd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}