{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take top 10% from first Generation\n",
    "\n",
    "With crossover create new 80% from my 10%\n",
    "\n",
    "The rest 20% are totally random\n",
    "\n",
    "Repeat for each iteration!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the new Methodology on Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "define all functions..\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow and other libraries\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential, clone_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "# Import the Iris data set from sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Define the output size\n",
    "output_size = 3 # change this according to your problem\n",
    "\n",
    "print(\"define all functions..\")\n",
    "\n",
    "# Define the custom loss function\n",
    "##### OLD VERSION #####\n",
    "# def custom_loss(y_true, y_pred):\n",
    "#     \"\"\" \n",
    "#     y_ture [batch_size x output_shape]\n",
    "    \n",
    "#     return [batch_size x 1]\n",
    "#     \"\"\"\n",
    "#     y_true_ind = tf.map_fn(fn = lambda t: tf.argmax(t), elems=y_true, dtype=tf.int64)\n",
    "#     y_pred_ind = tf.map_fn(fn = lambda t: tf.argmax(t), elems=y_pred, dtype=tf.int64)\n",
    "#     total_loss = tf.map_fn(fn = lambda t: tf.cast(t[0] == t[1], tf.float32), elems=(y_true_ind, y_pred_ind), dtype=tf.float32)\n",
    "#     return total_loss\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    y_true_ind = tf.argmax(y_true, axis=1)\n",
    "    y_pred_ind = tf.argmax(y_pred, axis=1)\n",
    "    total_loss = tf.cast(tf.equal(y_true_ind, y_pred_ind), tf.float32)\n",
    "    return total_loss\n",
    "\n",
    "# Define the fitness function\n",
    "def fitness(model, x, y, batch_size):\n",
    "    # Evaluate the model on the data and return the accuracy\n",
    "    # t = time.time()\n",
    "    y_pred = model.predict(x, batch_size=batch_size, verbose=0)\n",
    "    # tt = time.time()\n",
    "    accuracy = tf.reduce_mean(custom_loss(y, y_pred)).numpy()\n",
    "    # ttt = time.time()\n",
    "    \n",
    "    # print(\"Predict: {:.2f}s, Loss: {:.2f}s\".format(tt - t, ttt - tt))\n",
    "    return accuracy\n",
    "\n",
    "# Define the mutation function\n",
    "def mutate(weights, mutation_rate):\n",
    "    # Apply random changes to the weights with a given probability\n",
    "    new_weights = []\n",
    "    for w in weights:\n",
    "        shape = w.shape\n",
    "        w = w.flatten()\n",
    "        for i in range(len(w)):\n",
    "            if np.random.random() < mutation_rate:\n",
    "                w[i] += np.random.normal(0, 0.3) # add a small random noise  95%  -0.9 -- 0.9\n",
    "        w = w.reshape(shape)\n",
    "        new_weights.append(w)\n",
    "    return new_weights\n",
    "\n",
    "# Define the crossover function\n",
    "def crossover(weights1, weights2, crossover_rate):\n",
    "    # Combine the weights of two parents with a given probability\n",
    "    new_weights1 = []\n",
    "    new_weights2 = []\n",
    "    for w1, w2 in zip(weights1, weights2):\n",
    "        shape = w1.shape\n",
    "        w1 = w1.flatten()\n",
    "        w2 = w2.flatten()\n",
    "        if np.random.random() < crossover_rate:\n",
    "            \n",
    "            ### Probablly this piece of code takes too long to run\n",
    "            # # Choose a random crossover point\n",
    "            # point = np.random.randint(len(w1))\n",
    "            # # Swap the weights after the crossover point\n",
    "            # w1[point:], w2[point:] = w2[point:], w1[point:]\n",
    "            \n",
    "            w1, w2 = w2, w1\n",
    "            \n",
    "        w1 = w1.reshape(shape)\n",
    "        w2 = w2.reshape(shape)\n",
    "        new_weights1.append(w1)\n",
    "        new_weights2.append(w2)\n",
    "    return new_weights1, new_weights2\n",
    "\n",
    "# Define the selection function\n",
    "def select(population, fitnesses, elitism_rate):\n",
    "    # Sort the population by fitness in descending order\n",
    "    sorted_indices = np.argsort(fitnesses)[::-1]\n",
    "    population = [population[i] for i in sorted_indices]\n",
    "    fitnesses = [fitnesses[i] for i in sorted_indices]\n",
    "\n",
    "    # Keep the best individuals as elites\n",
    "    n_elites = int(elitism_rate * len(population))\n",
    "    elites = population[:n_elites]\n",
    "\n",
    "    # Select the rest of the individuals by roulette wheel method\n",
    "    selected = []\n",
    "    total_fitness = np.sum(fitnesses[n_elites:])\n",
    "    probabilities = [f / total_fitness for f in fitnesses[n_elites:]]\n",
    "    for _ in range(len(population) - n_elites):\n",
    "        r = np.random.random()\n",
    "        s = 0\n",
    "        for i in range(n_elites, len(population)):\n",
    "            s += probabilities[i - n_elites]\n",
    "            if s >= r:\n",
    "                selected.append(population[i])\n",
    "                break\n",
    "    \n",
    "    # Return the elites and the selected individuals\n",
    "    return elites + selected\n",
    "\n",
    "# Define the build and compile model function\n",
    "def build_and_compile_model():\n",
    "    model = Sequential([\n",
    "        Input(shape=(4,)),\n",
    "        Dense(2*output_size, activation=\"relu\"),\n",
    "        Dense(8*output_size, activation=\"relu\"),\n",
    "        Dense(32*output_size, activation=\"relu\"),\n",
    "        Dense(output_size)\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=custom_loss,\n",
    "                  optimizer=Adam(0.001))\n",
    "    \n",
    "    model.build(input_shape=(3,))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the genetic algorithm parameters\n",
    "population_size = 100 # number of individuals in the population\n",
    "mutation_rate = 0.1 # probability of mutation for each gene\n",
    "crossover_rate = 0.8 # probability of crossover for each pair of parents\n",
    "elitism_rate = 0.1 # fraction of the best individuals to keep in each generation\n",
    "max_generations = 100 # maximum number of generations to run the algorithm\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1683829691.3833776"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), TensorShape([150, 3]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data...\n",
      "Initialise models...\n",
      "Start learning...\n"
     ]
    }
   ],
   "source": [
    "print(\"Prepare data...\")\n",
    "\n",
    "# Load the data and the labels\n",
    "data = load_iris()\n",
    "x = data.data # shape = (150, 4)\n",
    "y = data.target # shape = (150,)\n",
    "y = tf.one_hot(y, depth=output_size) # convert to one-hot encoding\n",
    "\n",
    "print(\"Initialise models...\")\n",
    "\n",
    "# Initialize the population with random models\n",
    "population = []\n",
    "for _ in range(population_size):\n",
    "    model = build_and_compile_model()\n",
    "    population.append(model)\n",
    "\n",
    "print(\"Start learning...\")\n",
    "\n",
    "# Run the genetic algorithm for a given number of generations\n",
    "for generation in range(max_generations):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Evaluate the fitness of each individual\n",
    "    fitnesses = []\n",
    "    for model in population:\n",
    "        fitnesses.append(fitness(model, x, y, batch_size))\n",
    "        \n",
    "    fit_finish_time = time.time()\n",
    "    \n",
    "    # Print the average and best fitness in the current generation\n",
    "    avg_fitness = np.mean(fitnesses)\n",
    "    best_fitness = np.max(fitnesses)\n",
    "    print(f\"Generation {generation}: Average fitness = {avg_fitness}, Best fitness = {best_fitness}\")\n",
    "\n",
    "    # Check if the best fitness is 1.0 (perfect accuracy)\n",
    "    if best_fitness == 1.0:\n",
    "        print(\"Found the optimal solution!\")\n",
    "        break\n",
    "\n",
    "    # Select the individuals for the next generation\n",
    "    population = select(population, fitnesses, elitism_rate)\n",
    "    \n",
    "    population_select_time = time.time()\n",
    "\n",
    "    # Apply crossover and mutation to generate new individuals\n",
    "    new_population = []\n",
    "    while len(new_population) < population_size - 20:\n",
    "        # Choose two parents randomly\n",
    "        parent1 = np.random.choice(population)\n",
    "        parent2 = np.random.choice(population)\n",
    "\n",
    "        # Clone parents' models\n",
    "        child1 = clone_model(parent1)\n",
    "        child2 = clone_model(parent2)\n",
    "\n",
    "        # Get parents' weights\n",
    "        weights1 = parent1.get_weights()\n",
    "        weights2 = parent2.get_weights()\n",
    "\n",
    "        # Apply crossover\n",
    "        child_weights1, child_weights2 = crossover(weights1, weights2, crossover_rate)\n",
    "\n",
    "        # Apply mutation\n",
    "        child_weights1 = mutate(child_weights1, mutation_rate)\n",
    "        child_weights2 = mutate(child_weights2, mutation_rate)\n",
    "\n",
    "        # Set new weights for child models\n",
    "        child1.set_weights(child_weights1)\n",
    "        child2.set_weights(child_weights2)\n",
    "\n",
    "        # Add children to the new population\n",
    "        new_population.append(child1)\n",
    "        new_population.append(child2)\n",
    "        \n",
    "    new_population_time = time.time()\n",
    "    \n",
    "    print(\"Time for fit: {:.2f}s, Selection: {:.2f}s, new_population_time: {:.2f}s\".format(fit_finish_time-start_time,\n",
    "                                                                                           population_select_time-fit_finish_time,\n",
    "                                                                                           new_population_time-population_select_time))\n",
    "        \n",
    "    # Add 20 completely random models\n",
    "    for _ in range(20):\n",
    "        model = build_and_compile_model()\n",
    "        new_population.append(model)\n",
    "    \n",
    "    # Replace the old population with the new one\n",
    "    population = new_population\n",
    "\n",
    "# Find the best model in the final population\n",
    "best_model = None\n",
    "best_fitness = 0.0\n",
    "for model in population:\n",
    "    f = fitness(model, x, y)\n",
    "    if f > best_fitness:\n",
    "        best_model = model\n",
    "        best_fitness = f\n",
    "\n",
    "# Print the best model and its weights\n",
    "print(\"The best model is:\")\n",
    "best_model.summary()\n",
    "print(\"The weights are:\")\n",
    "for w in best_model.get_weights():\n",
    "    print(w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tomnet_n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
